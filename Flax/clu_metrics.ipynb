{"cells":[{"cell_type":"markdown","metadata":{},"source":["What `clu` helps is not direct computation of cross entropy, etc. Instead, it helps JAX friendly metrics computation as the name stands for Common Loop Utils. \n","\n","* https://colab.research.google.com/github/google/CommonLoopUtils/blob/main/clu_synopsis.ipynb\n","* https://github.com/google/CommonLoopUtils/blob/main/clu/metrics.py#L326"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from clu import metrics\n","import flax\n","import jax.numpy as jnp"]},{"cell_type":"markdown","metadata":{},"source":["# Metric computation"]},{"cell_type":"markdown","metadata":{},"source":["Metrics are computed in three steps. Remember that Jax needs functional code."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["Array(0.75, dtype=float32)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# 1. Compute intermediate values from model outputs\n","accuracy_batch1 = metrics.Accuracy.from_model_output(\n","    logits=jnp.array([[-1., 1.], [1., -1.]]),\n","    labels=jnp.array([0, 0]),  # i.e. 1st incorrect, 2nd correct\n",")\n","accuracy_batch2 = metrics.Accuracy.from_model_output(\n","    logits=jnp.array([[-1., 1.], [1., -1.]]),\n","    labels=jnp.array([1, 0]),  # i.e. both correct\n",")\n","\n","# 2. Intermediate values are aggregated\n","accuracy = accuracy_batch1\n","accuracy = accuracy.merge(accuracy_batch2)\n","\n","# 3. Final metrics\n","accuracy.compute()"]},{"cell_type":"markdown","metadata":{},"source":["# Average"]},{"cell_type":"markdown","metadata":{},"source":["https://github.com/google/CommonLoopUtils/blob/main/clu/metrics.py#L96"]},{"cell_type":"markdown","metadata":{},"source":["Demonstrate what metrics.Metric APIs do"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["@flax.struct.dataclass\n","class MyAverage(metrics.Metric):\n","    total: jnp.array\n","    count: jnp.array\n","    \n","    \n","    @classmethod\n","    def from_model_output(cls, value: jnp.array, **_) -> metrics.Metric:\n","        # This name is really confusing due to \"model_output\", but all it does\n","        # is just take what's given as parameter to compute the metric.\n","        # The model itself is not referenced.\n","        return cls(total=value, count=jnp.prod(jnp.array(value.shape)))\n","    \n","    def merge(self, other: metrics.Metric) -> metrics.Metric:\n","        return type(self)(total=self.total + other.total, \n","                          count=self.count + other.count)\n","    \n","    def compute(self):\n","        return self.total / self.count     "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.5\n","MyAverage(total=Array(3, dtype=int32), count=Array(2., dtype=float32))\n"]}],"source":["average = None\n","data = jnp.array([1, 2])\n","for value in data:\n","    update = MyAverage.from_model_output(value)\n","    average = update if average is None else average.merge(update)\n","    \n","# Computed avg.\n","print(average.compute())\n","\n","# See total and count.\n","print(average)"]},{"cell_type":"markdown","metadata":{},"source":["Actual Average class in clu"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average(total=Array(3, dtype=int32), count=Array(2, dtype=int32))\n"]}],"source":["average = None\n","data = jnp.array([[1],[2]])\n","for value in data:\n","    # CLU Average also keeps track of total and count but it can considers mask\n","    # (which we don't demonstrate here).\n","    update = metrics.Average.from_model_output(value)\n","    average = update if average is None else average.merge(update)\n","print(average)"]},{"cell_type":"markdown","metadata":{},"source":["# Collection of metrics"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy(total=Array(3., dtype=float32), count=Array(4, dtype=int32))\n","0.75\n"]}],"source":["@flax.struct.dataclass\n","class MyMetrics(metrics.Collection):\n","    accuracy: metrics.Accuracy\n","    \n","my_metrics = None\n","\n","# List of array of (input, label) pairs\n","data = [(0, jnp.array(0)), \n","        (1, jnp.array(0)),\n","        (2, jnp.array(1)),\n","        (3, jnp.array(1))]\n","\n","def model(x):\n","    # If input is 0, predict label 0.\n","    if x == 0:\n","        return jnp.array([0.7, 0.2, 0.1])\n","    # Otherwise, predict label 1.\n","    else:\n","        return jnp.array([0.4, 0.5, 0.1])\n","    \n","# Given the above, accuracy should be 3/4 = 0.75\n","# input 0 -> predicted 0, actual 0\n","# input 1 -> predicted 1, actual 0\n","# input 2 -> predicted 1, actual 1\n","# input 3 -> predicted 1, actual 1\n","\n","for inputs, labels in data:\n","    logits = model(inputs)\n","    # single_from_model_ouptut is when pmap isn't involved. Under pmap, use\n","    # gather_from_model_output.\n","    # \n","    # The function essentially returns:\n","    # {\n","    #   'accuracy': Accuracy.from_model_output(logits=logits, labels=labels)\n","    # }\n","    #\n","    # Accuracy.from_model_output requires logits and lables where logits is\n","    # jnp.int32 array while logits's ndim is lables.ndim + 1. In our example,\n","    # label:  jnp.array(3).dtype == jnp.int32\n","    #         jnp.array(3).ndim == 0\n","    # logits: jnp.array([0.7, 0.2, 0.1]) == 1\n","    #\n","    # If batched, their ndim will be 1 and 2 for each of label and logits,\n","    # respectively.\n","    update = MyMetrics.single_from_model_output(logits=logits, labels=labels)\n","    my_metrics = update if my_metrics is None else my_metrics.merge(update)\n","    \n","print(my_metrics.accuracy)\n","print(my_metrics.accuracy.compute())"]},{"cell_type":"markdown","metadata":{},"source":["Example with multiple metrics"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["my_collection.compute()={'accuracy': Array(1., dtype=float32), 'loss': Array(0.1, dtype=float32), 'loss_std': Array(0., dtype=float32)}\n","update.compute()={'accuracy': Array(0., dtype=float32), 'loss': Array(0.7, dtype=float32), 'loss_std': Array(0., dtype=float32)}\n","my_collection.compute()={'accuracy': Array(0.5, dtype=float32), 'loss': Array(0.4, dtype=float32), 'loss_std': Array(0.29999995, dtype=float32)}\n"]}],"source":["@flax.struct.dataclass\n","class MyCollection(metrics.Collection):\n","    # Accuracy uses loss and logits.\n","    accuracy: metrics.Accuracy\n","    # Using 'from_output', specify what to collect from \n","    # single_from_model_output parameters, i.e., collect 'loss'.\n","    loss: metrics.Average.from_output('loss')\n","    loss_std: metrics.Std.from_output('loss')\n","\n","my_collection = MyCollection.single_from_model_output(\n","    # correct\n","    loss=0.1, logits=jnp.array([0.9, 0.1]), labels=jnp.array(0))\n","print(f'{my_collection.compute()=}')\n","update = MyCollection.single_from_model_output(\n","    # wrong as logit says label 0\n","    loss=0.7, logits=jnp.array([0.8, 0.2]), labels=jnp.array(1))\n","print(f'{update.compute()=}')\n","my_collection = my_collection.merge(update)\n","print(f'{my_collection.compute()=}')"]},{"cell_type":"markdown","metadata":{},"source":["# Collecting metrics"]},{"cell_type":"markdown","metadata":{},"source":["We can collect numbers in the metrics and then use them for computing metrics on the host CPU, e.g., gather logits and labels but compute accuracy using sklearn. See https://github.com/google/CommonLoopUtils/blob/cdd17c5d5f69280d216ab47061ef9a87f3a0a5a4/clu/metrics.py#L326"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":"jax","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
