{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from typing import Any, Callable, Sequence\n",
    "from jax import lax, random, numpy as jnp\n",
    "import flax\n",
    "from flax import linen as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with Flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Dense(features=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters & initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'bias': (5,), 'kernel': (10, 5)}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key1, key2 = random.split(random.PRNGKey(0))\n",
    "x = random.normal(key1, (10, ))\n",
    "# model.init(PRNGKey, dummy data)\n",
    "params = model.init(key2, x)\n",
    "jax.tree_util.tree_map(lambda x: x.shape, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "{'params': {'bias': (5,), 'kernel': (10, 5)}}\n"
     ]
    }
   ],
   "source": [
    "output, params = model.init_with_output(key2, x)\n",
    "print(output.shape)\n",
    "print(jax.tree_util.tree_map(lambda x: x.shape, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-1.4309565 ,  0.68059814, -0.47063   , -0.00443757,  0.61720204],      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(params, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'flax.core.frozen_dict.FrozenDict'>\n",
      "x shape: (20, 10) ; y shape: (20, 5)\n"
     ]
    }
   ],
   "source": [
    "n_samples = 20\n",
    "x_dim = 10\n",
    "y_dim = 5\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "k1, k2 = random.split(key)\n",
    "W = random.normal(k1, (x_dim, y_dim))\n",
    "b = random.normal(k2, (y_dim, ))\n",
    "true_params = flax.core.freeze({'params': {'bias': b, 'kernel': W}})\n",
    "print(type(true_params))\n",
    "\n",
    "key_sample, key_noise = random.split(k1)\n",
    "x_samples = random.normal(key_sample, (n_samples, x_dim))\n",
    "y_samples = (jnp.dot(x_samples, W) + b \n",
    "             + 0.1 * random.normal(key_noise, (n_samples, y_dim)))\n",
    "print('x shape:', x_samples.shape, '; y shape:', y_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def mse(params, x_batched, y_batched):\n",
    "    def squared_error(x, y):\n",
    "        pred = model.apply(params, x)\n",
    "        return jnp.inner(y-pred, y-pred) / 2.0\n",
    "    return jnp.mean(jax.vmap(squared_error)(x_batched, y_batched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for \"true W, b: 0.023639798\n",
      "Loss step 0: 35.717175\n",
      "Loss step 10: 0.52654123\n",
      "Loss step 20: 0.11472414\n",
      "Loss step 30: 0.037997153\n",
      "Loss step 40: 0.019133301\n",
      "Loss step 50: 0.013885747\n",
      "Loss step 60: 0.012306851\n",
      "Loss step 70: 0.011808872\n",
      "Loss step 80: 0.011647595\n",
      "Loss step 90: 0.011594624\n",
      "Loss step 100: 0.011577098\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.3\n",
    "print('Loss for \"true W, b:', mse(true_params, x_samples, y_samples))\n",
    "loss_grad_fn = jax.value_and_grad(mse)\n",
    "\n",
    "@jax.jit\n",
    "def update_params(params, learning_rate, grads):\n",
    "    params = jax.tree_util.tree_map(\n",
    "        lambda p, g: p - learning_rate * g, params, grads)\n",
    "    return params\n",
    "\n",
    "for i in range(101):\n",
    "    loss_val, grads = loss_grad_fn(params, x_samples, y_samples)\n",
    "    params = update_params(params, learning_rate, grads)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Loss step {i}:', loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing with Optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m learning_rate \u001b[39m=\u001b[39m \u001b[39m0.3\u001b[39m\n\u001b[1;32m      3\u001b[0m tx \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39madam(learning_rate\u001b[39m=\u001b[39mlearning_rate)\n\u001b[0;32m----> 4\u001b[0m opt_state \u001b[39m=\u001b[39m tx\u001b[39m.\u001b[39minit(params)\n\u001b[1;32m      5\u001b[0m loss_grad_fn \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mvalue_and_grad(mse)\n\u001b[1;32m      6\u001b[0m params \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minit(random\u001b[39m.\u001b[39mPRNGKey(\u001b[39m0\u001b[39m), x_samples)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "learning_rate = 0.3\n",
    "tx = optax.adam(learning_rate=learning_rate)\n",
    "opt_state = tx.init(params)\n",
    "loss_grad_fn = jax.value_and_grad(mse)\n",
    "params = model.init(random.PRNGKey(0), x_samples)\n",
    "\n",
    "for i in range(101):\n",
    "    loss_val, grads = loss_grad_fn(params, x_samples, y_samples)\n",
    "    updates, opt_state = tx.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Loss step {i}: {loss_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bytes output: b'\\x81\\xa6params\\x82\\xa4bias\\xc7!\\x01\\x93\\x91\\x05\\xa7float32\\xc4\\x14\\xd44\\xb9\\xbf\\x82\\xa5\\x01\\xc0\\x1f{\\x05@=[\\x9c?\\xb6E\\x80\\xbf\\xa6kernel\\xc7\\xd6\\x01\\x93\\x92\\n\\x05\\xa7float32\\xc4\\xc8I\\x8f\\x80?\\x88\\x82=>\\n\\xc71=p\\xdam\\xbf4j\\xb3>\\x86\\xcc\\xdc?\\xa9Y~?\\xdd\\xd0\\x95?W\\xc2\\x8d?^~\\xd9\\xbd\\x90\\xad\\x98\\xbfT8\\x92>\\x1f\\xa9\\xb5?n\\x9e\\xfd=\\x16\\x1d\\xa8\\xbf\\x86{\\x98\\xbf\\xf5\\x88?\\xbe\\x8e\\\\$=\\x8cg\\xa9?l\\x1f\\xad=X\\xa5\\x0c>\\x1f\\xfd\\xae?\\xaf\\xd6\\xa8\\xbfe\\xd4\\t?ax\\x0f\\xc0\\x96\\x8c\\x0f?\\xc8\\xd0P?\\x96:\\xa6>\\x0f\\xc7\\t?\\xc8Qg?F\\xcf\\xc3\\xbeT\\t\\xdf?)\\x08\\x8a?\\xfd\\x10\\x01\\xbf\\xf6\\x14m?\\xbe\\xa1w?\\xe8)\\xa8\\xbfr)\\xab>&NP?\\xef\\xbe\\x99\\xbfI=\\x82?\\xf8-\\x1f\\xbf\\xad\\\\\\x89??n\\xeb\\xbf\\xe4\\x1c\\xeb\\xbe\\x92T&\\xbf\\xa40\\xec>\\x99j\\x91\\xbf\\xda?/\\xbfR\\xc2)>'\n",
      "Dict output: {'params': {'bias': Array([-1.4469247, -2.0257268,  2.0856397,  1.2215344, -1.0021274],      dtype=float32), 'kernel': Array([[ 1.0043727 ,  0.18506825,  0.04340271, -0.92911434,  0.35041964],\n",
      "       [ 1.7249916 ,  0.9935556 ,  1.1704365 ,  1.1074933 , -0.10619806],\n",
      "       [-1.1927967 ,  0.285586  ,  1.4192237 ,  0.12383734, -1.3133876 ],\n",
      "       [-1.1912696 , -0.18704589,  0.04012733,  1.3234725 ,  0.08453259],\n",
      "       [ 0.13734949,  1.3670996 , -1.3190516 ,  0.53839713, -2.2417223 ],\n",
      "       [ 0.5607389 ,  0.81568575,  0.32466573,  0.53819364,  0.90359163],\n",
      "       [-0.38244075,  1.7424722 ,  1.078374  , -0.5041655 ,  0.9261011 ],\n",
      "       [ 0.96731174, -1.3137789 ,  0.33430058,  0.81369245, -1.2011393 ],\n",
      "       [ 1.0174953 , -0.6217952 ,  1.0731407 , -1.839302  , -0.4592048 ],\n",
      "       [-0.64972794,  0.4613086 , -1.1360656 , -0.68456805,  0.16578034]],      dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "from flax import serialization\n",
    "bytes_output = serialization.to_bytes(params)\n",
    "dict_output = serialization.to_state_dict(params)\n",
    "print('Bytes output:', bytes_output)\n",
    "print('Dict output:', dict_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'bias': array([-1.4469247, -2.0257268,  2.0856397,  1.2215344, -1.0021274],\n",
       "        dtype=float32),\n",
       "  'kernel': array([[ 1.0043727 ,  0.18506825,  0.04340271, -0.92911434,  0.35041964],\n",
       "         [ 1.7249916 ,  0.9935556 ,  1.1704365 ,  1.1074933 , -0.10619806],\n",
       "         [-1.1927967 ,  0.285586  ,  1.4192237 ,  0.12383734, -1.3133876 ],\n",
       "         [-1.1912696 , -0.18704589,  0.04012733,  1.3234725 ,  0.08453259],\n",
       "         [ 0.13734949,  1.3670996 , -1.3190516 ,  0.53839713, -2.2417223 ],\n",
       "         [ 0.5607389 ,  0.81568575,  0.32466573,  0.53819364,  0.90359163],\n",
       "         [-0.38244075,  1.7424722 ,  1.078374  , -0.5041655 ,  0.9261011 ],\n",
       "         [ 0.96731174, -1.3137789 ,  0.33430058,  0.81369245, -1.2011393 ],\n",
       "         [ 1.0174953 , -0.6217952 ,  1.0731407 , -1.839302  , -0.4592048 ],\n",
       "         [-0.64972794,  0.4613086 , -1.1360656 , -0.68456805,  0.16578034]],\n",
       "        dtype=float32)}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params here is a template\n",
    "serialization.from_bytes(params, bytes_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
