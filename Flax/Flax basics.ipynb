{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from typing import Any, Callable, Sequence\n",
    "from jax import lax, random, numpy as jnp\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with Flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Dense(features=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters & initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'bias': (5,), 'kernel': (10, 5)}}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key1, key2 = random.split(random.PRNGKey(0))\n",
    "x = random.normal(key1, (10, ))\n",
    "# model.init(PRNGKey, dummy data)\n",
    "params = model.init(key2, x)\n",
    "jax.tree_util.tree_map(lambda x: x.shape, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "{'params': {'bias': (5,), 'kernel': (10, 5)}}\n"
     ]
    }
   ],
   "source": [
    "output, params = model.init_with_output(key2, x)\n",
    "print(output.shape)\n",
    "print(jax.tree_util.tree_map(lambda x: x.shape, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-1.4309565 ,  0.68059814, -0.47063   , -0.00443757,  0.61720204],      dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(params, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'flax.core.frozen_dict.FrozenDict'>\n",
      "x shape: (20, 10) ; y shape: (20, 5)\n"
     ]
    }
   ],
   "source": [
    "n_samples = 20\n",
    "x_dim = 10\n",
    "y_dim = 5\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "k1, k2 = random.split(key)\n",
    "W = random.normal(k1, (x_dim, y_dim))\n",
    "b = random.normal(k2, (y_dim, ))\n",
    "true_params = flax.core.freeze({'params': {'bias': b, 'kernel': W}})\n",
    "print(type(true_params))\n",
    "\n",
    "key_sample, key_noise = random.split(k1)\n",
    "x_samples = random.normal(key_sample, (n_samples, x_dim))\n",
    "y_samples = (jnp.dot(x_samples, W) + b \n",
    "             + 0.1 * random.normal(key_noise, (n_samples, y_dim)))\n",
    "print('x shape:', x_samples.shape, '; y shape:', y_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def mse(params, x_batched, y_batched):\n",
    "    def squared_error(x, y):\n",
    "        pred = model.apply(params, x)\n",
    "        return jnp.inner(y-pred, y-pred) / 2.0\n",
    "    return jnp.mean(jax.vmap(squared_error)(x_batched, y_batched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for \"true W, b: 0.023639798\n",
      "Loss step 0: 35.717175\n",
      "Loss step 10: 0.52654123\n",
      "Loss step 20: 0.11472414\n",
      "Loss step 30: 0.037997153\n",
      "Loss step 40: 0.019133301\n",
      "Loss step 50: 0.013885747\n",
      "Loss step 60: 0.012306851\n",
      "Loss step 70: 0.011808872\n",
      "Loss step 80: 0.011647595\n",
      "Loss step 90: 0.011594624\n",
      "Loss step 100: 0.011577098\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.3\n",
    "print('Loss for \"true W, b:', mse(true_params, x_samples, y_samples))\n",
    "loss_grad_fn = jax.value_and_grad(mse)\n",
    "\n",
    "@jax.jit\n",
    "def update_params(params, learning_rate, grads):\n",
    "    params = jax.tree_util.tree_map(\n",
    "        lambda p, g: p - learning_rate * g, params, grads)\n",
    "    return params\n",
    "\n",
    "for i in range(101):\n",
    "    loss_val, grads = loss_grad_fn(params, x_samples, y_samples)\n",
    "    params = update_params(params, learning_rate, grads)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Loss step {i}:', loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing with Optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss step 0: 35.479736328125\n",
      "Loss step 10: 4.361007213592529\n",
      "Loss step 20: 1.258549690246582\n",
      "Loss step 30: 0.4513617157936096\n",
      "Loss step 40: 0.15732677280902863\n",
      "Loss step 50: 0.0579988956451416\n",
      "Loss step 60: 0.02834184840321541\n",
      "Loss step 70: 0.017301736399531364\n",
      "Loss step 80: 0.014532424509525299\n",
      "Loss step 90: 0.01267541665583849\n",
      "Loss step 100: 0.011985315941274166\n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "learning_rate = 0.3\n",
    "tx = optax.adam(learning_rate=learning_rate)\n",
    "opt_state = tx.init(params)\n",
    "loss_grad_fn = jax.value_and_grad(mse)\n",
    "params = model.init(random.PRNGKey(0), x_samples)\n",
    "\n",
    "for i in range(101):\n",
    "    loss_val, grads = loss_grad_fn(params, x_samples, y_samples)\n",
    "    updates, opt_state = tx.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Loss step {i}: {loss_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bytes output: b'\\x81\\xa6params\\x82\\xa4bias\\xc7!\\x01\\x93\\x91\\x05\\xa7float32\\xc4\\x14\\xd44\\xb9\\xbf\\x82\\xa5\\x01\\xc0\\x1f{\\x05@=[\\x9c?\\xb6E\\x80\\xbf\\xa6kernel\\xc7\\xd6\\x01\\x93\\x92\\n\\x05\\xa7float32\\xc4\\xc8I\\x8f\\x80?\\x88\\x82=>\\n\\xc71=p\\xdam\\xbf4j\\xb3>\\x86\\xcc\\xdc?\\xa9Y~?\\xdd\\xd0\\x95?W\\xc2\\x8d?^~\\xd9\\xbd\\x90\\xad\\x98\\xbfT8\\x92>\\x1f\\xa9\\xb5?n\\x9e\\xfd=\\x16\\x1d\\xa8\\xbf\\x86{\\x98\\xbf\\xf5\\x88?\\xbe\\x8e\\\\$=\\x8cg\\xa9?l\\x1f\\xad=X\\xa5\\x0c>\\x1f\\xfd\\xae?\\xaf\\xd6\\xa8\\xbfe\\xd4\\t?ax\\x0f\\xc0\\x96\\x8c\\x0f?\\xc8\\xd0P?\\x96:\\xa6>\\x0f\\xc7\\t?\\xc8Qg?F\\xcf\\xc3\\xbeT\\t\\xdf?)\\x08\\x8a?\\xfd\\x10\\x01\\xbf\\xf6\\x14m?\\xbe\\xa1w?\\xe8)\\xa8\\xbfr)\\xab>&NP?\\xef\\xbe\\x99\\xbfI=\\x82?\\xf8-\\x1f\\xbf\\xad\\\\\\x89??n\\xeb\\xbf\\xe4\\x1c\\xeb\\xbe\\x92T&\\xbf\\xa40\\xec>\\x99j\\x91\\xbf\\xda?/\\xbfR\\xc2)>'\n",
      "Dict output: {'params': {'bias': Array([-1.4469247, -2.0257268,  2.0856397,  1.2215344, -1.0021274],      dtype=float32), 'kernel': Array([[ 1.0043727 ,  0.18506825,  0.04340271, -0.92911434,  0.35041964],\n",
      "       [ 1.7249916 ,  0.9935556 ,  1.1704365 ,  1.1074933 , -0.10619806],\n",
      "       [-1.1927967 ,  0.285586  ,  1.4192237 ,  0.12383734, -1.3133876 ],\n",
      "       [-1.1912696 , -0.18704589,  0.04012733,  1.3234725 ,  0.08453259],\n",
      "       [ 0.13734949,  1.3670996 , -1.3190516 ,  0.53839713, -2.2417223 ],\n",
      "       [ 0.5607389 ,  0.81568575,  0.32466573,  0.53819364,  0.90359163],\n",
      "       [-0.38244075,  1.7424722 ,  1.078374  , -0.5041655 ,  0.9261011 ],\n",
      "       [ 0.96731174, -1.3137789 ,  0.33430058,  0.81369245, -1.2011393 ],\n",
      "       [ 1.0174953 , -0.6217952 ,  1.0731407 , -1.839302  , -0.4592048 ],\n",
      "       [-0.64972794,  0.4613086 , -1.1360656 , -0.68456805,  0.16578034]],      dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "from flax import serialization\n",
    "bytes_output = serialization.to_bytes(params)\n",
    "dict_output = serialization.to_state_dict(params)\n",
    "print('Bytes output:', bytes_output)\n",
    "print('Dict output:', dict_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'bias': array([-1.4469247, -2.0257268,  2.0856397,  1.2215344, -1.0021274],\n",
       "        dtype=float32),\n",
       "  'kernel': array([[ 1.0043727 ,  0.18506825,  0.04340271, -0.92911434,  0.35041964],\n",
       "         [ 1.7249916 ,  0.9935556 ,  1.1704365 ,  1.1074933 , -0.10619806],\n",
       "         [-1.1927967 ,  0.285586  ,  1.4192237 ,  0.12383734, -1.3133876 ],\n",
       "         [-1.1912696 , -0.18704589,  0.04012733,  1.3234725 ,  0.08453259],\n",
       "         [ 0.13734949,  1.3670996 , -1.3190516 ,  0.53839713, -2.2417223 ],\n",
       "         [ 0.5607389 ,  0.81568575,  0.32466573,  0.53819364,  0.90359163],\n",
       "         [-0.38244075,  1.7424722 ,  1.078374  , -0.5041655 ,  0.9261011 ],\n",
       "         [ 0.96731174, -1.3137789 ,  0.33430058,  0.81369245, -1.2011393 ],\n",
       "         [ 1.0174953 , -0.6217952 ,  1.0731407 , -1.839302  , -0.4592048 ],\n",
       "         [-0.64972794,  0.4613086 , -1.1360656 , -0.68456805,  0.16578034]],\n",
       "        dtype=float32)}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params here is a template\n",
    "serialization.from_bytes(params, bytes_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized parameter shape:\n",
      " {'params': {'layers_0': {'bias': (3,), 'kernel': (4, 3)}, 'layers_1': {'bias': (4,), 'kernel': (3, 4)}, 'layers_2': {'bias': (5,), 'kernel': (4, 5)}}}\n",
      "Output:\n",
      " (4, 5)\n"
     ]
    }
   ],
   "source": [
    "# nn.Module is dataclass\n",
    "class ExplicitMLP(nn.Module):\n",
    "    features: Sequence[int]\n",
    "    \n",
    "    # called at the end of __post_init__\n",
    "    def setup(self):\n",
    "        self.layers = [nn.Dense(feat) for feat in self.features]\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for i, lyr in enumerate(self.layers):\n",
    "            x = lyr(x)\n",
    "            if i != len(self.layers) - 1:\n",
    "                x = nn.relu(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
    "x = random.uniform(key1, (4, 4))\n",
    "\n",
    "model = ExplicitMLP(features=[3, 4, 5])\n",
    "params = model.init(key2, x)\n",
    "y = model.apply(params, x)\n",
    "\n",
    "print('Initialized parameter shape:\\n', jax.tree_util.tree_map(jnp.shape, params))\n",
    "print('Output:\\n', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized parameters:\n",
      " {'params': {'layer_0': {'bias': (3,), 'kernel': (4, 3)}, 'layer_1': {'bias': (4,), 'kernel': (3, 4)}, 'layer_2': {'bias': (5,), 'kernel': (4, 5)}}}\n",
      "Output shape:\n",
      " (4, 5)\n"
     ]
    }
   ],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    features: Sequence[int]\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for i, feat in enumerate(self.features):\n",
    "            x = nn.Dense(feat, name=f\"layer_{i}\")(x)\n",
    "            if i != len(self.features) - 1:\n",
    "                x = nn.relu(x)\n",
    "        return x\n",
    "        \n",
    "key1, key2 = jax.random.split(jax.random.PRNGKey(0), 2)\n",
    "x = jax.random.normal(key1, (4, 4))\n",
    "\n",
    "model = SimpleMLP(features=[3, 4, 5])\n",
    "params = model.init(key2, x)\n",
    "y = model.apply(params, x)\n",
    "\n",
    "print('Initialized parameters:\\n', jax.tree_util.tree_map(jnp.shape, params))\n",
    "print('Output shape:\\n', y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized parameters:\n",
      " {'params': {'bias': (3,), 'kernel': (4, 3)}}\n",
      "Output shape:\n",
      " (4, 3)\n"
     ]
    }
   ],
   "source": [
    "class SimpleDense(nn.Module):\n",
    "    features: int\n",
    "    kernel_init: Callable = nn.initializers.lecun_normal()\n",
    "    bias_init: Callable = nn.initializers.zeros_init()\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        # Need input.shape to be in setup().\n",
    "        kernel = self.param('kernel',\n",
    "                            # init_fn\n",
    "                            self.kernel_init,\n",
    "                            # init_args to init_fn\n",
    "                            (inputs.shape[-1], self.features))\n",
    "        y = lax.dot_general(\n",
    "            inputs, kernel,\n",
    "            # ((lhs_contracting_dims, rhs_contracting_dims),\n",
    "            #  (lhs_batch_dims, rhs_batch_dims))\n",
    "            (((inputs.ndim - 1,), (0,)), ((), ())))\n",
    "        bias = self.param('bias', self.bias_init, (self.features,))\n",
    "        return y + bias\n",
    "    \n",
    "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
    "x = random.uniform(key1, (4, 4))\n",
    "\n",
    "model = SimpleDense(features=3)\n",
    "params = model.init(key2, x)\n",
    "y = model.apply(params, x)\n",
    "\n",
    "print('Initialized parameters:\\n', jax.tree_map(jnp.shape, params))\n",
    "print('Output shape:\\n', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and collection of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized variables:\n",
      " {'batch_stats': {'mean': Array([0., 0., 0., 0., 0.], dtype=float32)}, 'params': {'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}\n",
      "Updated state:\n",
      " {'batch_stats': {'mean': Array([[0.01, 0.01, 0.01, 0.01, 0.01]], dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "class BiasAdderWithRunningMean(nn.Module):\n",
    "    decay: float = 0.99\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        is_initialized = self.has_variable('batch_stats', 'mean')\n",
    "        ra_mean = self.variable('batch_stats', 'mean',\n",
    "                                lambda s: jnp.zeros(s), x.shape[1:])\n",
    "        \n",
    "        # This probably isn't needed. \n",
    "        # https://github.com/google/flax/issues/3260\n",
    "        # mean = ra_mean.value  # Either get the value or trigger init.\n",
    "        \n",
    "        # bias is a param while ra_mean is a variable.\n",
    "        bias = self.param('bias', lambda rng, shape: jnp.zeros(shape), x.shape[1:])\n",
    "        if is_initialized:\n",
    "            # Without keepdims, we get (5,) instead of (1,5). Not sure if it \n",
    "            # matters though.\n",
    "            ra_mean.value = self.decay * ra_mean.value + (1.0 - self.decay) * jnp.mean(x, axis=0, keepdims=True)\n",
    "        return x - ra_mean.value + bias\n",
    "    \n",
    "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
    "x = jnp.ones((10,5))\n",
    "model = BiasAdderWithRunningMean()\n",
    "variables = model.init(key1, x)\n",
    "print('Initialized variables:\\n', variables)\n",
    "y, updated_state = model.apply(variables, x, mutable=['batch_stats'])\n",
    "print('Updated state:\\n', updated_state)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we update variables and get the new params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial variables:\n",
      "{'batch_stats': {'mean': Array([0., 0., 0., 0., 0.], dtype=float32)}, 'params': {'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}\n",
      "Updated state:\n",
      "{'batch_stats': {'mean': Array([[0.01, 0.01, 0.01, 0.01, 0.01]], dtype=float32)}}\n",
      "Updated variables:\n",
      "FrozenDict({\n",
      "    params: {\n",
      "        bias: Array([0., 0., 0., 0., 0.], dtype=float32),\n",
      "    },\n",
      "    batch_stats: {\n",
      "        mean: Array([[0.01, 0.01, 0.01, 0.01, 0.01]], dtype=float32),\n",
      "    },\n",
      "})\n",
      "---------------\n",
      "Updated state:\n",
      "{'batch_stats': {'mean': Array([[0.0299, 0.0299, 0.0299, 0.0299, 0.0299]], dtype=float32)}}\n",
      "Updated variables:\n",
      "FrozenDict({\n",
      "    params: {\n",
      "        bias: Array([0., 0., 0., 0., 0.], dtype=float32),\n",
      "    },\n",
      "    batch_stats: {\n",
      "        mean: Array([[0.0299, 0.0299, 0.0299, 0.0299, 0.0299]], dtype=float32),\n",
      "    },\n",
      "})\n",
      "---------------\n",
      "Updated state:\n",
      "{'batch_stats': {'mean': Array([[0.059601, 0.059601, 0.059601, 0.059601, 0.059601]], dtype=float32)}}\n",
      "Updated variables:\n",
      "FrozenDict({\n",
      "    params: {\n",
      "        bias: Array([0., 0., 0., 0., 0.], dtype=float32),\n",
      "    },\n",
      "    batch_stats: {\n",
      "        mean: Array([[0.059601, 0.059601, 0.059601, 0.059601, 0.059601]], dtype=float32),\n",
      "    },\n",
      "})\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "print('Initial variables:')\n",
    "print(variables)\n",
    "for val in [1., 2., 3.]:\n",
    "    x = val * jnp.ones((10, 5))\n",
    "    # model.apply() needs params and variables as input, but it returns\n",
    "    # updated variables only. When there were no variables, model.apply()\n",
    "    # returns y only, e.g., y = model.apply(params, x)\n",
    "    y, updated_state = model.apply(variables, x, mutable=['batch_stats'])\n",
    "    # Merge params and updated_state into a new variables dict.\n",
    "    old_state, params = flax.core.pop(variables, 'params')\n",
    "    variables = flax.core.freeze({'params': params, **updated_state})\n",
    "    print('Updated state:')\n",
    "    print(updated_state)\n",
    "    print('Updated variables:')\n",
    "    print(variables)\n",
    "    print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there's an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0049999906\n",
      "Updated state:\n",
      " {'batch_stats': {'mean': Array([[0.01, 0.01, 0.01, 0.01, 0.01]], dtype=float32)}}\n",
      "Params:\n",
      " {'bias': Array([0.004, 0.004, 0.004, 0.004, 0.004], dtype=float32)}\n",
      "-------------------------\n",
      "Loss: 0.012640525\n",
      "Updated state:\n",
      " {'batch_stats': {'mean': Array([[0.0199, 0.0199, 0.0199, 0.0199, 0.0199]], dtype=float32)}}\n",
      "Params:\n",
      " {'bias': Array([0.01036, 0.01036, 0.01036, 0.01036, 0.01036], dtype=float32)}\n",
      "-------------------------\n",
      "Loss: 0.0187037\n",
      "Updated state:\n",
      " {'batch_stats': {'mean': Array([[0.029701, 0.029701, 0.029701, 0.029701, 0.029701]], dtype=float32)}}\n",
      "Params:\n",
      " {'bias': Array([0.0180964, 0.0180964, 0.0180964, 0.0180964, 0.0180964], dtype=float32)}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "@partial(jax.jit, static_argnums=(0, 1))\n",
    "def update_step(tx, apply_fn, x, opt_state, params, state):\n",
    "    \n",
    "    def loss(params):\n",
    "        y, updated_state = apply_fn({'params': params, **state},\n",
    "                                    x, mutable=list(state.keys()))\n",
    "        l = ((x - y) ** 2).sum()\n",
    "        return l, updated_state\n",
    "    \n",
    "    (l, state), grads = jax.value_and_grad(loss, has_aux=True)(params)\n",
    "    updates, opt_state = tx.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return opt_state, params, state, l\n",
    "\n",
    "x = jnp.ones((10, 5))\n",
    "variables = model.init(random.PRNGKey(0), x)\n",
    "state, params = flax.core.pop(variables, 'params')\n",
    "del variables\n",
    "tx = optax.sgd(learning_rate=0.02)\n",
    "opt_state = tx.init(params)\n",
    "\n",
    "for _ in range(3):\n",
    "    opt_state, params, state, loss = update_step(\n",
    "        tx, model.apply, x, opt_state, params, state)\n",
    "    print('Loss:', loss)\n",
    "    print('Updated state:\\n', state)\n",
    "    print('Params:\\n', params)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [TrainState](https://flax.readthedocs.io/en/latest/_modules/flax/training/train_state.html#TrainState) use below for encapsulating params and optax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss @ 0: 4.21584\n",
      "Loss @ 100: 1.5112355\n",
      "Loss @ 200: 1.2084138\n",
      "Loss @ 300: 1.1742883\n",
      "Loss @ 400: 1.1704139\n",
      "Loss @ 500: 1.16997\n",
      "Loss @ 600: 1.1699189\n",
      "Loss @ 700: 1.1699128\n",
      "Loss @ 800: 1.1699121\n",
      "Loss @ 900: 1.1699121\n",
      "Loss @ 1000: 1.1699121\n"
     ]
    }
   ],
   "source": [
    "x_key, noise_key, model_key = jax.random.split(jax.random.PRNGKey(0), 3)\n",
    "xs = jax.random.normal(x_key, (100, 1))\n",
    "noise = jax.random.normal(noise_key, (100, 1))\n",
    "W, b = 2, -1\n",
    "ys = xs + noise + b\n",
    "\n",
    "@jax.jit\n",
    "def apply_model(state, xs, ys):\n",
    "\n",
    "    def loss_fn(params, xs, ys):\n",
    "        # Can't use {'params': state.params} here because it then\n",
    "        # is not functional.\n",
    "        yhats = state.apply_fn({'params': params}, xs)\n",
    "        loss = jnp.mean((ys - yhats) ** 2)\n",
    "        return loss\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params, xs, ys)\n",
    "    return loss, grads\n",
    "\n",
    "@jax.jit\n",
    "def update_model(state, grads):\n",
    "    return state.apply_gradients(grads=grads)\n",
    "\n",
    "class SingleLayerDNN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(1)(x)\n",
    "        return x\n",
    "    \n",
    "model = SingleLayerDNN()\n",
    "params = model.init(model_key, xs)['params']\n",
    "\n",
    "state = TrainState.create(apply_fn=model.apply, params=params, tx=optax.sgd(0.005))\n",
    "for i in range(1001):\n",
    "    loss, grads = apply_model(state, xs, ys)\n",
    "    state = update_model(state, grads)\n",
    "    if i % 100 == 0:\n",
    "        print(f'Loss @ {i}:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "yhats = state.apply_fn({'params': state.params}, xs)\n",
    "plt.scatter(xs, yhats, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
