{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from typing import Any\n",
    "from jax import numpy as jnp\n",
    "from flax import linen as nn\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 20:51:55.994684: W pjrt_plugin/src/mps_client.cc:535] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Max\n",
      "\n",
      "systemMemory: 96.00 GB\n",
      "maxCacheSize: 36.00 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_key, noise_key, params_key, dropout_key = jax.random.split(\n",
    "    jax.random.PRNGKey(0), 4)\n",
    "xs = jax.random.normal(x_key, (100, 1))\n",
    "noise = jax.random.normal(noise_key, (100, 1))\n",
    "W, b = 2, -1\n",
    "ys = xs + noise + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    num_neurons: int\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, training: bool):\n",
    "        x = nn.Dense(self.num_neurons)(x)\n",
    "        x = nn.Dropout(rate=0.5, deterministic=not training)(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "  key: jax.random.KeyArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state: TrainState, xs, ys, dropout_key):\n",
    "    dropout_train_key = jax.random.fold_in(\n",
    "        key=dropout_key, data=state.step)\n",
    "    \n",
    "    def loss_fn(params):\n",
    "        yhats = state.apply_fn(\n",
    "            {'params': params}, xs, training=True, \n",
    "            rngs={'dropout': dropout_train_key})\n",
    "        loss = jnp.mean((ys - yhats) ** 2)\n",
    "        return loss\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: 6.6528730392456055\n",
      "Iteration 100: 5.362330436706543\n",
      "Iteration 200: 4.739670753479004\n",
      "Iteration 300: 4.24291467666626\n",
      "Iteration 400: 4.084765911102295\n",
      "Iteration 500: 3.82289719581604\n",
      "Iteration 600: 3.664264440536499\n",
      "Iteration 700: 3.4753434658050537\n",
      "Iteration 800: 2.919456720352173\n",
      "Iteration 900: 2.8462142944335938\n",
      "Iteration 1000: 2.6043999195098877\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(num_neurons=3)\n",
    "variables = model.init(params_key, xs, training=False)\n",
    "params = variables['params']\n",
    "\n",
    "state = TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    key=dropout_key,\n",
    "    tx=optax.adam(1e-3),\n",
    ")\n",
    "\n",
    "for i in range(1001):\n",
    "    state, loss = train_step(state, xs, ys, dropout_key)\n",
    "    if i % 100 == 0:\n",
    "        print(f'Iteration {i}: {loss}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 839183663 3740430601]\n"
     ]
    }
   ],
   "source": [
    "print(state.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from flax.linen.stochastic import KeyArray\n",
    "from flax.training import train_state\n",
    "from jax import random\n",
    "from jax import lax\n",
    "from flax.linen.module import merge_param\n",
    "from typing import Sequence\n",
    "\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "  key: jax.random.KeyArray\n",
    "\n",
    "\n",
    "class MyModelMultiple(nn.Module):\n",
    "    num_neurons: int\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, training: bool):\n",
    "        x = nn.Dense(self.num_neurons)(x)\n",
    "        x = nn.Dropout(rate=0.5, deterministic=not training)(x)\n",
    "        x = nn.Dropout(rate=0.5, deterministic=not training)(x)\n",
    "        x = nn.Dropout(rate=0.5, deterministic=not training)(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state: TrainState, xs, ys, dropout_key):\n",
    "    dropout_train_key = jax.random.fold_in(\n",
    "        key=dropout_key, data=state.step)\n",
    "    \n",
    "    def loss_fn(params):\n",
    "        yhats = state.apply_fn(\n",
    "            {'params': params}, xs, training=True, \n",
    "            # Each of 'Dropout' layers in the model has unique 'scope name' which is\n",
    "            # folded in when computing the random numbers. Thus, those\n",
    "            # there layers are okay with sharing the same key.\n",
    "            # If interested, see https://github.com/google/flax/discussions/3262.\n",
    "            rngs={'dropout': dropout_train_key})\n",
    "        loss = jnp.mean((ys - yhats) ** 2)\n",
    "        return loss\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Init\n",
      "* Training\n",
      "Iteration 0: 31.82681655883789\n",
      "Iteration 100: 16.837251663208008\n",
      "Iteration 200: 16.39636993408203\n",
      "Iteration 300: 13.929004669189453\n",
      "Iteration 400: 10.109065055847168\n",
      "Iteration 500: 13.120767593383789\n",
      "Iteration 600: 9.250357627868652\n",
      "Iteration 700: 10.172189712524414\n",
      "Iteration 800: 8.768033981323242\n",
      "Iteration 900: 10.029900550842285\n",
      "Iteration 1000: 3.9830234050750732\n"
     ]
    }
   ],
   "source": [
    "model = MyModelMultiple(num_neurons=3)\n",
    "rng1, rng2, rng3 = jax.random.split(dropout_key, 3)\n",
    "print(\"* Init\")\n",
    "variables = model.init(params_key, xs, training=False)\n",
    "params = variables['params']\n",
    "\n",
    "state = TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    key=dropout_key,\n",
    "    tx=optax.adam(1e-3),\n",
    ")\n",
    "\n",
    "print(\"* Training\")\n",
    "for i in range(1001):\n",
    "    state, loss = train_step(state, xs, ys, dropout_key)\n",
    "    if i % 100 == 0:\n",
    "        print(f'Iteration {i}: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
