{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM that returns sequences and stateful. If that's not necessary, just use [nn.scan](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/_autosummary/flax.linen.scan.html). Also, see below for learable initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "from flax.training import train_state\n",
    "import logging\n",
    "import numpy as np\n",
    "import optax\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flax.struct.dataclass\n",
    "class Carry:\n",
    "  carry1: Any\n",
    "  carry2: Any\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "  \"\"\"Carry around the carry for stateful LSTM.\"\"\"\n",
    "  carry: Carry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceLSTMCell(nn.Module):\n",
    "    \"\"\"LSTMCell that can return sequences.\"\"\"\n",
    "\n",
    "    features: int\n",
    "    return_sequences: bool\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, inputs):\n",
    "        sequence_length = inputs.shape[1]\n",
    "\n",
    "        outputs = []\n",
    "        lstm_cell = nn.LSTMCell(features=self.features)\n",
    "        for t in range(sequence_length):\n",
    "            carry, output = lstm_cell(carry, inputs[:, t, :])\n",
    "            if self.return_sequences:\n",
    "                outputs.append(output)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            # stack along seq dim\n",
    "            return carry, jnp.stack(outputs, axis=1)\n",
    "        else:\n",
    "            return carry, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    features: list[int]\n",
    "    \n",
    "    def setup(self):\n",
    "        self.lstm1 = SequenceLSTMCell(features=self.features[0], \n",
    "                                      return_sequences=True, name=\"sequence_lstm\")\n",
    "        self.lstm2 = SequenceLSTMCell(features=self.features[1], \n",
    "                                      return_sequences=False, name=\"lstm\")\n",
    "        self.dense = nn.Dense(features=1, name=\"dense\")\n",
    "\n",
    "    def __call__(self, carry, x):\n",
    "        carry1, carry2 = carry.carry1, carry.carry2\n",
    "        carry1, x = self.lstm1(carry=carry1, inputs=x)\n",
    "        carry2, x = self.lstm2(carry=carry2, inputs=x)\n",
    "        x = self.dense(x)\n",
    "        return Carry(carry1, carry2), x\n",
    "    \n",
    "    def initialize_carry(self):\n",
    "        carry1 = (jnp.zeros((self.features[0],)), jnp.zeros((self.features[0],)))\n",
    "        carry2 = (jnp.zeros((self.features[0],)), jnp.zeros((self.features[0],)))\n",
    "        return Carry(carry1, carry2)\n",
    "    \n",
    "# If you don't need stateful LSTM:\n",
    "#\n",
    "# class Model(nn.Module):\n",
    "#     features: list[int]\n",
    "#   \n",
    "#     def setup(self):\n",
    "#         self.lstm1 = SequenceLSTMCell(features=self.features[0], \n",
    "#                                       return_sequences=True, name=\"sequence_lstm\")\n",
    "#         self.lstm2 = SequenceLSTMCell(features=self.features[1], \n",
    "#                                       return_sequences=False, name=\"lstm\")\n",
    "#         self.dense = nn.Dense(features=1, name=\"dense\")\n",
    "#\n",
    "#         # Initialize the carry as a learnable parameter.\n",
    "#         # These are now part of params that's learned just like W, b in Dense\n",
    "#         # are learned.\n",
    "#         self.carry1 = self.param('carry1_lstm1', nn.initializers.zeros, \n",
    "#                                  (self.features[0],))\n",
    "#         self.carry2 = self.param('carry2_lstm2', nn.initializers.zeros, \n",
    "#                                  (self.features[1],))\n",
    "#\n",
    "#     def __call__(self, x):\n",
    "#         carry1 = self.carry1\n",
    "#         carry2 = self.carry2\n",
    "#         carry1, x = self.lstm1(carry=carry1, inputs=x)\n",
    "#         carry2, x = self.lstm2(carry=carry2, inputs=x)\n",
    "#         x = self.dense(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jax.jit\n",
    "def apply_model(state, X, y):\n",
    "    \"\"\"Computes gradients, loss and accuracy for a single batch.\"\"\"\n",
    "    \n",
    "    def mean_squared_error(y, yhat):\n",
    "        return jnp.mean((y - yhat)**2)\n",
    "\n",
    "    def compute_loss_fn(params, carry):\n",
    "        carry, yhat = state.apply_fn({\"params\": params}, carry, X)\n",
    "        loss = mean_squared_error(y, yhat)\n",
    "        return loss, carry\n",
    "\n",
    "    carry, yhat = state.apply_fn({\"params\": state.params}, state.carry, X)\n",
    "    grad_fn = jax.value_and_grad(compute_loss_fn, has_aux=True)\n",
    "    (loss, carry), grads = grad_fn(state.params, state.carry)\n",
    "    return carry, loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update_model(state, grads):\n",
    "    return state.apply_gradients(grads=grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, dataset_fn):\n",
    "    epoch_loss = []\n",
    "    for i, (X, y) in enumerate(dataset_fn()):\n",
    "        carry, loss, grads = apply_model(state, X, y)\n",
    "        state = update_model(state, grads)\n",
    "        state = state.replace(carry=carry)\n",
    "        epoch_loss.append(loss)\n",
    "    train_loss = np.mean(epoch_loss)\n",
    "    return state, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "sequence_length = 3\n",
    "\n",
    "def datagen():\n",
    "    x = jnp.arange(300)\n",
    "    y = jnp.sin(x * 0.01)\n",
    "    y = y + jnp.roll(y, shift=1) - 2 * jnp.roll(y, shift=1)\n",
    "    y = y + jax.random.normal(jax.random.PRNGKey(0), y.shape) * 0.1\n",
    "    \n",
    "    for i in range(0, len(x) - sequence_length - batch_size + 1):\n",
    "        X_batch = [x[i + j:i + j + sequence_length][:, np.newaxis] for j in range(batch_size)]\n",
    "        y_batch = [y[i + j + sequence_length] for j in range(batch_size)]\n",
    "        yield jnp.stack(X_batch), jnp.stack(y_batch)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n",
      "2023-08-15 19:01:26.798834: W pjrt_plugin/src/mps_client.cc:535] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"builtin.module\"() ({\n",
      "  \"func.func\"() ({\n",
      "  ^bb0(%arg0: tensor<5x5xf32>):\n",
      "    %0 = \"mhlo.constant\"() {value = dense<-1> : tensor<5x5xi32>} : () -> tensor<5x5xsi32>\n",
      "    %1 = \"mhlo.constant\"() {value = dense<0.000000e+00> : tensor<5x5xf32>} : () -> tensor<5x5xf32>\n",
      "    %2:2 = \"mhlo.custom_call\"(%arg0) {api_version = 1 : i32, backend_config = \"\", call_target_name = \"Qr\", called_computations = [], has_side_effect = false} : (tensor<5x5xf32>) -> (tensor<5x5xf32>, tensor<5xf32>)\n",
      "    %3 = \"mhlo.custom_call\"(%2#0, %2#1) {api_version = 1 : i32, backend_config = \"\", call_target_name = \"ProductOfElementaryHouseholderReflectors\", called_computations = [], has_side_effect = false} : (tensor<5x5xf32>, tensor<5xf32>) -> tensor<5x5xf32>\n",
      "    %4 = \"mhlo.iota\"() {iota_dimension = 0 : i64} : () -> tensor<5xsi32>\n",
      "    %5 = \"mhlo.broadcast_in_dim\"(%4) {broadcast_dimensions = dense<0> : tensor<1xi64>} : (tensor<5xsi32>) -> tensor<5x5xsi32>\n",
      "    %6 = \"mhlo.add\"(%5, %0) : (tensor<5x5xsi32>, tensor<5x5xsi32>) -> tensor<5x5xsi32>\n",
      "    %7 = \"mhlo.iota\"() {iota_dimension = 0 : i64} : () -> tensor<5xsi32>\n",
      "    %8 = \"mhlo.broadcast_in_dim\"(%7) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<5xsi32>) -> tensor<5x5xsi32>\n",
      "    %9 = \"mhlo.compare\"(%6, %8) {compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction GE>} : (tensor<5x5xsi32>, tensor<5x5xsi32>) -> tensor<5x5xi1>\n",
      "    %10 = \"mhlo.select\"(%9, %1, %2#0) : (tensor<5x5xi1>, tensor<5x5xf32>, tensor<5x5xf32>) -> tensor<5x5xf32>\n",
      "    \"func.return\"(%3, %10) : (tensor<5x5xf32>, tensor<5x5xf32>) -> ()\n",
      "  }) {arg_attrs = [{jax.arg_info = \"a\", mhlo.sharding = \"{replicated}\"}], function_type = (tensor<5x5xf32>) -> (tensor<5x5xf32>, tensor<5x5xf32>), res_attrs = [{jax.result_info = \"[0]\"}, {jax.result_info = \"[1]\"}], sym_name = \"main\", sym_visibility = \"public\"} : () -> ()\n",
      "}) {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32, sym_name = \"jit_qr\"} : () -> ()\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "UNKNOWN: /var/folders/09/9zmlsg756kxfcbx6l3tdhf600000gn/T/ipykernel_99180/857170341.py:14:28: error: failed to legalize operation 'mhlo.custom_call'\n/var/folders/09/9zmlsg756kxfcbx6l3tdhf600000gn/T/ipykernel_99180/857170341.py:14:28: note: see current operation: %4:2 = \"mhlo.custom_call\"(%arg0) {api_version = 1 : i32, backend_config = \"\", call_target_name = \"Qr\", called_computations = [], has_side_effect = false} : (tensor<5x5xf32>) -> (tensor<5x5xf32>, tensor<5xf32>)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m init_rng \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mPRNGKey(\u001b[39m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m carry \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minitialize_carry()\n\u001b[0;32m----> 5\u001b[0m params \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49minit(init_rng,\n\u001b[1;32m      6\u001b[0m                     carry\u001b[39m=\u001b[39;49mcarry, \n\u001b[1;32m      7\u001b[0m                     x\u001b[39m=\u001b[39;49mjnp\u001b[39m.\u001b[39;49mones((batch_size, sequence_length, \u001b[39m1\u001b[39;49m)))[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m state \u001b[39m=\u001b[39m TrainState\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     10\u001b[0m     apply_fn\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mapply,\n\u001b[1;32m     11\u001b[0m     params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m     12\u001b[0m     tx\u001b[39m=\u001b[39moptax\u001b[39m.\u001b[39madam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m),\n\u001b[1;32m     13\u001b[0m     carry\u001b[39m=\u001b[39mcarry)\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, carry, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, carry, x):\n\u001b[1;32m     12\u001b[0m     carry1, carry2 \u001b[39m=\u001b[39m carry\u001b[39m.\u001b[39mcarry1, carry\u001b[39m.\u001b[39mcarry2\n\u001b[0;32m---> 13\u001b[0m     carry1, x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm1(carry\u001b[39m=\u001b[39;49mcarry1, inputs\u001b[39m=\u001b[39;49mx)\n\u001b[1;32m     14\u001b[0m     carry2, x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm2(carry\u001b[39m=\u001b[39mcarry2, inputs\u001b[39m=\u001b[39mx)\n\u001b[1;32m     15\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(x)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mSequenceLSTMCell.__call__\u001b[0;34m(self, carry, inputs)\u001b[0m\n\u001b[1;32m     12\u001b[0m lstm_cell \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLSTMCell(features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(sequence_length):\n\u001b[0;32m---> 14\u001b[0m     carry, output \u001b[39m=\u001b[39m lstm_cell(carry, inputs[:, t, :])\n\u001b[1;32m     15\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_sequences:\n\u001b[1;32m     16\u001b[0m         outputs\u001b[39m.\u001b[39mappend(output)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.11/site-packages/flax/linen/recurrent.py:187\u001b[0m, in \u001b[0;36mLSTMCell.__call__\u001b[0;34m(self, carry, inputs)\u001b[0m\n\u001b[1;32m    170\u001b[0m dense_h \u001b[39m=\u001b[39m partial(\n\u001b[1;32m    171\u001b[0m     Dense,\n\u001b[1;32m    172\u001b[0m     features\u001b[39m=\u001b[39mhidden_features,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     param_dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_dtype,\n\u001b[1;32m    178\u001b[0m )\n\u001b[1;32m    179\u001b[0m dense_i \u001b[39m=\u001b[39m partial(\n\u001b[1;32m    180\u001b[0m     Dense,\n\u001b[1;32m    181\u001b[0m     features\u001b[39m=\u001b[39mhidden_features,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m     param_dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_dtype,\n\u001b[1;32m    186\u001b[0m )\n\u001b[0;32m--> 187\u001b[0m i \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgate_fn(dense_i(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mii\u001b[39m\u001b[39m'\u001b[39m)(inputs) \u001b[39m+\u001b[39m dense_h(name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhi\u001b[39;49m\u001b[39m'\u001b[39;49m)(h))\n\u001b[1;32m    188\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgate_fn(dense_i(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mif\u001b[39m\u001b[39m'\u001b[39m)(inputs) \u001b[39m+\u001b[39m dense_h(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhf\u001b[39m\u001b[39m'\u001b[39m)(h))\n\u001b[1;32m    189\u001b[0m g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_fn(dense_i(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mig\u001b[39m\u001b[39m'\u001b[39m)(inputs) \u001b[39m+\u001b[39m dense_h(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhg\u001b[39m\u001b[39m'\u001b[39m)(h))\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.11/site-packages/flax/linen/linear.py:226\u001b[0m, in \u001b[0;36mDense.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m@compact\u001b[39m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, inputs: Array) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[1;32m    218\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Applies a linear transformation to the inputs along the last dimension.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m    The transformed input.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m   kernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam(\n\u001b[1;32m    227\u001b[0m       \u001b[39m'\u001b[39;49m\u001b[39mkernel\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    228\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_init,\n\u001b[1;32m    229\u001b[0m       (jnp\u001b[39m.\u001b[39;49mshape(inputs)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures),\n\u001b[1;32m    230\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_dtype,\n\u001b[1;32m    231\u001b[0m   )\n\u001b[1;32m    232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m    233\u001b[0m     bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam(\n\u001b[1;32m    234\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_init, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures,), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_dtype\n\u001b[1;32m    235\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/tmp/jax-jax-v0.4.11/jax/_src/nn/initializers.py:568\u001b[0m, in \u001b[0;36morthogonal.<locals>.init\u001b[0;34m(key, shape, dtype)\u001b[0m\n\u001b[1;32m    566\u001b[0m matrix_shape \u001b[39m=\u001b[39m (n_cols, n_rows) \u001b[39mif\u001b[39;00m n_rows \u001b[39m<\u001b[39m n_cols \u001b[39melse\u001b[39;00m (n_rows, n_cols)\n\u001b[1;32m    567\u001b[0m A \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mnormal(key, matrix_shape, dtype)\n\u001b[0;32m--> 568\u001b[0m Q, R \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mqr(A)\n\u001b[1;32m    569\u001b[0m diag_sign \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39mbroadcast_to_rank(jnp\u001b[39m.\u001b[39msign(jnp\u001b[39m.\u001b[39mdiag(R)), rank\u001b[39m=\u001b[39mQ\u001b[39m.\u001b[39mndim)\n\u001b[1;32m    570\u001b[0m Q \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m diag_sign \u001b[39m# needed for a uniform distribution\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "File \u001b[0;32m~/tmp/jax-jax-v0.4.11/jax/_src/dispatch.py:465\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    461\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    462\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: UNKNOWN: /var/folders/09/9zmlsg756kxfcbx6l3tdhf600000gn/T/ipykernel_99180/857170341.py:14:28: error: failed to legalize operation 'mhlo.custom_call'\n/var/folders/09/9zmlsg756kxfcbx6l3tdhf600000gn/T/ipykernel_99180/857170341.py:14:28: note: see current operation: %4:2 = \"mhlo.custom_call\"(%arg0) {api_version = 1 : i32, backend_config = \"\", call_target_name = \"Qr\", called_computations = [], has_side_effect = false} : (tensor<5x5xf32>) -> (tensor<5x5xf32>, tensor<5xf32>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model(features=[5, 3])\n",
    "init_rng = jax.random.PRNGKey(42)\n",
    "carry = model.initialize_carry()\n",
    "\n",
    "params = model.init(init_rng,\n",
    "                    carry=carry, \n",
    "                    x=jnp.ones((batch_size, sequence_length, 1)))['params']\n",
    "\n",
    "state = TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optax.adam(learning_rate=1e-3),\n",
    "    carry=carry)\n",
    "\n",
    "for i in range(10):\n",
    "    state, train_loss = train_epoch(state, datagen)\n",
    "    # Across batches, carry is not kept.\n",
    "    state = state.replace(carry=model.initialize_carry())\n",
    "    logging.info(f\"Epoch: {i:4d}, train_loss: {train_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
